# Self_Attention（自注意力机制）

是一个NetWork架构 核心思想

```
通过计算序列中每个元素与其他所有元素的关联权重，动态生成每个元素的上下文相关表示
```

在之前的网络架构中 我们输入是一个向量

![image-20250407103516482](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407103516482.png)dna s

但是我们不代表不会遇到 输入是一排向量的问题

![image-20250407103535420](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407103535420.png)

例如文字处理 处理句子 那么这个向量就是可变的

例如声音讯号

![image-20250407103813938](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407103813938.png)

# FC方法

![image-20250407104705583](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407104705583.png)

但是这里是有问题的 因为 SAW 完全是一样的

这里有一个解决方法 可以通过 附近的内容来判定

![image-20250407104808757](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407104808757.png)

这样就可以考虑好附近的window 

SelfATTention 就是会吃掉一整个 向量的data

然后输入多少个向量 就输出多少个 到Network中 

![image-20250407105030740](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407105030740.png)

他们都是考虑了一整个 输入向量的data 而输出的FC中向量

那么这样 我们就其实考虑了整个输入向量的data

# 如何运作

![image-20250407105253957](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407105253957.png)

这是大概模型

如何产生呢 

1. 通过a1 找出 这个input中 相关的其他向量

   找出一个window中 哪些对于输出a1是有帮助的 我们用数值b来表示

   ## 如何找到相关性？

   使用计算attention的模组

   例如 可以使用 dot-product

   ![image-20250407105504558](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407105504558.png)

   输出关联性

   ![image-20250407105625216](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407105625216.png)

   这样我们就可以输出attention的得分

   ![image-20250407105651750](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407105651750.png)

   计算完毕后 运作 softmax 函数 得到一排输出a 通过a抽出和a1最有关系的data

   ![image-20250407105837339](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407105837339.png)

其实整个 Self attention 都是一串矩阵乘法

![image-20250407110824604](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407110824604.png)

INPUT 分别乘上3个学习到的矩阵 计算出QKV

然后通过

![image-20250407110859598](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407110859598.png)

得到一个A 通过一次softmax  最后乘上V  就可以得到 自注意力后的 向量

所以如下

![image-20250407110954811](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407110954811.png)

学习的参数 就只有  Wq Wk Wv 是需要通过训练资料找出来

# 多头Self attention

多个相关性的时候就需要使用这个

![image-20250407111134597](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407111134597.png)

然后通过一个 n类的作为一个输入

![image-20250407111353892](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407111353892.png)

# 塞入位置的信息

例如我们通过词性训练 那么位置信息可能也是很重要的

我们记为 e 我们只要把e + a_input 就可以了

![image-20250407111616620](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407111616620.png)

# Self Attention 用在影像上

CNN  转变为向量 完全可以使用self attention处理图片

Self Attention会考虑整张图片 那么就是复杂的CNN

这里就是自己学习 receptive filed

![image-20250407113623390](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250407113623390.png)
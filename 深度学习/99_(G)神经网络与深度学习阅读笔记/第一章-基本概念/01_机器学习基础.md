# 深度学习基础说明

深度学习是机器学习的一个分支，是指一类问题以及解决这类问题的方法

## 贡献度分配问题

是机器学习通过多组线形或者非线性的部件加工 我们对每个部件的贡献 无从知晓 这里我们就体现了贡献度分配问题

在深度学习中 贡献度分配问题影响了 我们如何更好的调参

```
一种可以比较好解决贡献度分配问题的模型是人工神经网络（Artifi-cial Neural Network，ANN）．人工神经网络，也简称神经网络
```

这里我们通过人脑引出神经网络 人可以通过神经元处理参数 最终输出语言图像等 

神经网络数学模型就是通过这个设想提出的数学模型

神经网络中存在两个特殊的类型 一个是输出 一个是输入

人工神经网络通过参数输入 输出特定功能 

如果可以通过机器在不断学习中自动输出参数 那么这就是深度学习

## 神经网络和深度学习

这两个不是一个东西 深度学习可以通过神经网络模型进行学习 就是通过神经网络数学模型 也可以通过其他模型学习，但是我们之前提出的 贡献分配度问题 可以被神经网络较好的解决，所以我们主流还是通过神经网络促进深度学习，一开始我们是通过神经网络解决分配问题 但是现在随着模型的强大，我们可以构建出促进决策 等更智能的方法

## 人工智能

```
图灵测试：“一个人在不接触对方的情况下，通过一种特殊的方式和对方进行一系列的问答．如果在相当长时间内，他无法根据这些问题判断对方是人还是计算机，那么就可以认为这个计算机是智能的”
```

```
从人工智能的萌芽时期开始，就有一些研究者尝试让机器来自动学习，即机器学习（Machine Learning，ML）
```

![image-20250325113414459](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325113414459.png)

这个图片揭露了人工智能的三个不同时期

## 机器学习

```
机器学习（Machine Learning，ML）是指从有限的观测数据中学习（或“猜测”）出具有一般性的规律
```

早期机器学习

```
传统的机器学习主要关注如何学习一个预测模型．一般需要首先将数据表示为一组特征（Feature），特征的表示形式可以是连续的数值、离散的符号或其他形式．然后将这些特征输入到预测模型，并输出预测结果．这类机器学习可以看作浅层学习（Shallow Learning）．浅层学习的一个重要特点是不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取．
```

主要是通过人工方法进行数据提取和构造

在实际任务中我们可以通过下面方法构建模型

![image-20250325113824889](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325113824889.png)

这里其实最重要的是前三部 数据预处理 特征提取和转换 通过人脑进行筛选 人工操作

这三部往往对 结果有着重大的影响，所以这种构建模型的方法 我们也叫做 **特征工程**

主要时间都消耗在 数据预处理 特征提取和转换

## 表示学习

表示学习 就是我们通过 数据可以自动提取特征 那么我们叫做表示学习

### 语言鸿沟

表示学习主要解决的问题是语言鸿沟 例如给定一个车的图片 需要输出结果 

底层特征 是 像素

高层语义信息 是车

如果我们将模型定义在 底层特征 那么对模型的要求过高 难以识别出高层语义

```
如果可以有一个好的表示在某种程度上能够反映出数据的高层语义特征，那么我们就能相对容易地构建后续的机器学习模型
```

```
在表示学习中，有两个核心问题：一是“什么是一个好的表示”；二是“如何学习到好的表示”
```

### 局部表示和分布式表示

#### 局部表示

假如我们需要通过数组存储颜色 那么如何存储呢

```
[0,0,0,0,1,0,0,0]  红色
[1,0,0,0,0,0,0,0]  蓝色

...
```

我们可以发现 这里包括了8种颜色 可以有效的快速的分辨出颜色这种方法我们就叫做局部表示 或者符号表示

即 对每一个颜色进行命名存储 一对一

**优点**

1） 具有更好的离散 可以通过人工更好的决策

2） 通常表示向量为 稀疏的二值向量

**缺点**

1）one-hot 向量的维数很高，且不能扩展．如果有一种新的颜色，我们就需要增加一维来表示；

```
例如 增加一个变为 [0,0,0,0,0,0,0,0,0]
```

2）不同颜色之间的相似度都为0，即我们无法知道“红色”和“中国红”的相似度要高于“红色”和“黑色”的相似度

```
假如 红色为 [1,0,0,0,0,0,0,0] 中国红为[0,1,0,0,0,0,0,0] 即使他们都是红色 通过局部表示无法判定他们有没有联系
```

#### 分布式表示

RGB就是一个分布式表示 通过无数种颜色 降低纬度到 3维 通过RGB 三种值来表示所有颜色 这样就会形成一个三维空间 我们的值就在三维空间里存储

这里就解决了 局部表示的两个缺点

![image-20250325115427227](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325115427227.png)

我们将高纬的坐标轴上的 **嵌入** 到低维空间中 

![image-20250325115519899](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325115519899.png)

## 深度学习

我们上面了解了表示学习 通过底层特征 表示出 高层语义

机器学习就是构建一个模型 可以通过 底层特征 中层特征 最终输出到高层语义中 从而提升模型预测准确率

![image-20250325115845056](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325115845056.png)

可以通过对比发现 我们减少了 **特征工程**

最开始我们聊到了**贡献度问题** 深度学习是无法通过局部分析好坏

例如我们下棋输了 我们需要分析哪一步下错了  这里就是贡献度问题

每个内部组件并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的延时性

目前深度学习主要采用的是神经网络模型 使用**误差反向传播算法** 只要超过一层都会输出贡献度

### 端到端学习

在传统学习中 类似写程序 会不同功能分配给不同函数 但是这里存在问题 

1） 不同模块需要单独调优

2） 模块对后续的影响很大 如果单一模块受损 那么整体存在影响

这里就提出了 **端到端学习** 没有局部 存在整体

只有输入-输出模式  直接优化全局任务 无需提供其他信息 也不需要人工监督

因此 端到端学习也要解决贡献度分配问题 所以使用神经网络的深度学习也可以理解为是一个端到端学习

## 神经网络

早期的神经科学家构造了一种模仿人脑神经系统的数学模型，称为人工神经网络，简称神经网络

```
神经元可以接收其他神经元的信息，也可以发送信息给其他神经元．神经元之间没有物理连接，两个“连接”的神经元之间留有 20 纳米左右的缝隙，并靠突触（Synapse）进行互联来传递信息，形成一个神经网络，即神经系统
一个神经元可被视为一种只有两种状态的细胞：兴奋和抑制
```

![image-20250325121351451](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325121351451.png)

### 人工神经网络

人工神经元 相互连接 变为节点  不同节点  之间的连接 被赋予不同的权重 代表对 对方连接的影响

每个节点是一个函数 来自其他节点的权重进行 计算 输出到一个激活函数中 获得一个新的活性值

人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自适应非线性动态系统

```
当神经元 A 的一个轴突和神经元 B 很近，足以对它产生影响，并且持续地、重复地参与了对神经元 B 的兴奋，那么在这两个神经元或其中之一会发生某种生长过程或新陈代谢变化，以致神经元 A 作为能使神经元 B 兴奋的细胞之一，它的效能加强了．”这个机制称为赫布理论（HebbianTheory）或赫布规则（Hebbian Rule，或 Hebb’s Rule）
```

人工神经网络诞生之初并不是用来解决机器学习问题

他主要是一个函数逼近问题

## 书本体系

![image-20250325121903545](https://raw.githubusercontent.com/Xioaruan912/pic/main/image-20250325121903545.png)

可以分为三大块：机器学习、神经网络和概率图模型

